{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comma police"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most widespread data storage format is the _comma separated value_ (csv) format.  \n",
    "The csv are tabular data: they are made of rows and columns. For the csv files to be good csv files, every rows must have the same number of columns; and conversely every column must have the same number of rows (yes, just as a good dataframe).  \n",
    "In general, though, there's nothing more than that: rows can be variable or observations, depending on who wrote the file.  \n",
    "The name _csv_ is given by the fact that each _value_ in a row is separated by a comma. And rows of value are separated by a break line.\n",
    "\n",
    "Comma separated value files are _plain text_ files: that means that you can open them with a simple text editor and see (and eventually, but don't do it!, edit) what's inside.\n",
    "\n",
    "In this lab we have one example here named \"addresses.csv\". You can open it in Jupyter Lab by double clicking on it. **Try that!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: what does it happen if you pick (in the Jupyter Lab viewer) a different delimeter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "addresses.csv works but challenge.csv does not i have no idea way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, csv files are a particular example of a wider class of files, where values are separated by _some_ delimiter. Common ones are tab delimited files, often shortened to _.tsv_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to read more about tidy data, and wide and long data, Hadley's book _Advanced R_ is THE place (he wrote the original paper). The relevant chapter is this one: http://r4ds.had.co.nz/tidy-data.html. Before the next lecture, to refresh about join operators, see this chapter: http://r4ds.had.co.nz/relational-data.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Into R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As almost always in this course, we are going to use the tidyverse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.7     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.9\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.2     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in a csv file, there's a dedicated function: `read_csv()`. Its output is a dataframe. Let's see, and **do read the red messages**.\n",
    "\n",
    "### NOTICE we are using read_csv, not read.csv, that is underscore (\"\\_\") not dot (\"\\.\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m5\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m6\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (6): John, Doe, 120 jefferson st., Riverside, NJ, 08075\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A spec_tbl_df: 5 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>John</th><th scope=col>Doe</th><th scope=col>120 jefferson st.</th><th scope=col>Riverside</th><th scope=col>NJ</th><th scope=col>08075</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Jack                 </td><td>McGinnis</td><td>220 hobo Av.                    </td><td>Phila      </td><td>PA</td><td>09119</td></tr>\n",
       "\t<tr><td>John \"Da Man\"        </td><td>Repici  </td><td>120 Jefferson St.               </td><td>Riverside  </td><td>NJ</td><td>08075</td></tr>\n",
       "\t<tr><td>Stephen              </td><td>Tyler   </td><td>7452 Terrace \"At the Plaza\" road</td><td>SomeTown   </td><td>SD</td><td>91234</td></tr>\n",
       "\t<tr><td>NA                   </td><td>Blankman</td><td>NA                              </td><td>SomeTown   </td><td>SD</td><td>00298</td></tr>\n",
       "\t<tr><td>Joan \"the bone\", Anne</td><td>Jet     </td><td>9th, at Terrace plc             </td><td>Desert City</td><td>CO</td><td>00123</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spec\\_tbl\\_df: 5 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " John & Doe & 120 jefferson st. & Riverside & NJ & 08075\\\\\n",
       " <chr> & <chr> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t Jack                  & McGinnis & 220 hobo Av.                     & Phila       & PA & 09119\\\\\n",
       "\t John \"Da Man\"         & Repici   & 120 Jefferson St.                & Riverside   & NJ & 08075\\\\\n",
       "\t Stephen               & Tyler    & 7452 Terrace \"At the Plaza\" road & SomeTown    & SD & 91234\\\\\n",
       "\t NA                    & Blankman & NA                               & SomeTown    & SD & 00298\\\\\n",
       "\t Joan \"the bone\", Anne & Jet      & 9th, at Terrace plc              & Desert City & CO & 00123\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spec_tbl_df: 5 × 6\n",
       "\n",
       "| John &lt;chr&gt; | Doe &lt;chr&gt; | 120 jefferson st. &lt;chr&gt; | Riverside &lt;chr&gt; | NJ &lt;chr&gt; | 08075 &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| Jack                  | McGinnis | 220 hobo Av.                     | Phila       | PA | 09119 |\n",
       "| John \"Da Man\"         | Repici   | 120 Jefferson St.                | Riverside   | NJ | 08075 |\n",
       "| Stephen               | Tyler    | 7452 Terrace \"At the Plaza\" road | SomeTown    | SD | 91234 |\n",
       "| NA                    | Blankman | NA                               | SomeTown    | SD | 00298 |\n",
       "| Joan \"the bone\", Anne | Jet      | 9th, at Terrace plc              | Desert City | CO | 00123 |\n",
       "\n"
      ],
      "text/plain": [
       "  John                  Doe      120 jefferson st.                Riverside  \n",
       "1 Jack                  McGinnis 220 hobo Av.                     Phila      \n",
       "2 John \"Da Man\"         Repici   120 Jefferson St.                Riverside  \n",
       "3 Stephen               Tyler    7452 Terrace \"At the Plaza\" road SomeTown   \n",
       "4 NA                    Blankman NA                               SomeTown   \n",
       "5 Joan \"the bone\", Anne Jet      9th, at Terrace plc              Desert City\n",
       "  NJ 08075\n",
       "1 PA 09119\n",
       "2 NJ 08075\n",
       "3 SD 91234\n",
       "4 SD 00298\n",
       "5 CO 00123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "addresses <- read_csv(file = \"addresses.csv\") \n",
    "\n",
    "addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it looks quite the same thing we have seen opening the file with Jupyter Lab.  \n",
    "So, what about that first row? It does not really look it's the name of variable, the _header_, rather just on row in the dataframe.  \n",
    "We can tell `read_csv()` that the first row is just like the other setting the argument `col_names` to false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m6\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m6\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (6): X1, X2, X3, X4, X5, X6\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A spec_tbl_df: 6 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>X1</th><th scope=col>X2</th><th scope=col>X3</th><th scope=col>X4</th><th scope=col>X5</th><th scope=col>X6</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>John                 </td><td>Doe     </td><td>120 jefferson st.               </td><td>Riverside  </td><td>NJ</td><td>08075</td></tr>\n",
       "\t<tr><td>Jack                 </td><td>McGinnis</td><td>220 hobo Av.                    </td><td>Phila      </td><td>PA</td><td>09119</td></tr>\n",
       "\t<tr><td>John \"Da Man\"        </td><td>Repici  </td><td>120 Jefferson St.               </td><td>Riverside  </td><td>NJ</td><td>08075</td></tr>\n",
       "\t<tr><td>Stephen              </td><td>Tyler   </td><td>7452 Terrace \"At the Plaza\" road</td><td>SomeTown   </td><td>SD</td><td>91234</td></tr>\n",
       "\t<tr><td>NA                   </td><td>Blankman</td><td>NA                              </td><td>SomeTown   </td><td>SD</td><td>00298</td></tr>\n",
       "\t<tr><td>Joan \"the bone\", Anne</td><td>Jet     </td><td>9th, at Terrace plc             </td><td>Desert City</td><td>CO</td><td>00123</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spec\\_tbl\\_df: 6 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " X1 & X2 & X3 & X4 & X5 & X6\\\\\n",
       " <chr> & <chr> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t John                  & Doe      & 120 jefferson st.                & Riverside   & NJ & 08075\\\\\n",
       "\t Jack                  & McGinnis & 220 hobo Av.                     & Phila       & PA & 09119\\\\\n",
       "\t John \"Da Man\"         & Repici   & 120 Jefferson St.                & Riverside   & NJ & 08075\\\\\n",
       "\t Stephen               & Tyler    & 7452 Terrace \"At the Plaza\" road & SomeTown    & SD & 91234\\\\\n",
       "\t NA                    & Blankman & NA                               & SomeTown    & SD & 00298\\\\\n",
       "\t Joan \"the bone\", Anne & Jet      & 9th, at Terrace plc              & Desert City & CO & 00123\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spec_tbl_df: 6 × 6\n",
       "\n",
       "| X1 &lt;chr&gt; | X2 &lt;chr&gt; | X3 &lt;chr&gt; | X4 &lt;chr&gt; | X5 &lt;chr&gt; | X6 &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| John                  | Doe      | 120 jefferson st.                | Riverside   | NJ | 08075 |\n",
       "| Jack                  | McGinnis | 220 hobo Av.                     | Phila       | PA | 09119 |\n",
       "| John \"Da Man\"         | Repici   | 120 Jefferson St.                | Riverside   | NJ | 08075 |\n",
       "| Stephen               | Tyler    | 7452 Terrace \"At the Plaza\" road | SomeTown    | SD | 91234 |\n",
       "| NA                    | Blankman | NA                               | SomeTown    | SD | 00298 |\n",
       "| Joan \"the bone\", Anne | Jet      | 9th, at Terrace plc              | Desert City | CO | 00123 |\n",
       "\n"
      ],
      "text/plain": [
       "  X1                    X2       X3                               X4         \n",
       "1 John                  Doe      120 jefferson st.                Riverside  \n",
       "2 Jack                  McGinnis 220 hobo Av.                     Phila      \n",
       "3 John \"Da Man\"         Repici   120 Jefferson St.                Riverside  \n",
       "4 Stephen               Tyler    7452 Terrace \"At the Plaza\" road SomeTown   \n",
       "5 NA                    Blankman NA                               SomeTown   \n",
       "6 Joan \"the bone\", Anne Jet      9th, at Terrace plc              Desert City\n",
       "  X5 X6   \n",
       "1 NJ 08075\n",
       "2 PA 09119\n",
       "3 NJ 08075\n",
       "4 SD 91234\n",
       "5 SD 00298\n",
       "6 CO 00123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "addresses <- \"addresses.csv\" %>%\n",
    "              read_csv(col_names = FALSE) \n",
    "\n",
    "addresses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better: all the rows of data are in the dataframe. But the name of the variable are really not informative.\n",
    "\n",
    "Sometimes you can read the names from a _data dictionary_ (a text file where the authors present the data, the way it is collected, the meaning of each variable). Sometimes you need to \"invent\" them for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m6\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m6\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (6): first_name, family_name, street_address, town, state, zip_code\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A spec_tbl_df: 6 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>first_name</th><th scope=col>family_name</th><th scope=col>street_address</th><th scope=col>town</th><th scope=col>state</th><th scope=col>zip_code</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>John                 </td><td>Doe     </td><td>120 jefferson st.               </td><td>Riverside  </td><td>NJ</td><td>08075</td></tr>\n",
       "\t<tr><td>Jack                 </td><td>McGinnis</td><td>220 hobo Av.                    </td><td>Phila      </td><td>PA</td><td>09119</td></tr>\n",
       "\t<tr><td>John \"Da Man\"        </td><td>Repici  </td><td>120 Jefferson St.               </td><td>Riverside  </td><td>NJ</td><td>08075</td></tr>\n",
       "\t<tr><td>Stephen              </td><td>Tyler   </td><td>7452 Terrace \"At the Plaza\" road</td><td>SomeTown   </td><td>SD</td><td>91234</td></tr>\n",
       "\t<tr><td>NA                   </td><td>Blankman</td><td>NA                              </td><td>SomeTown   </td><td>SD</td><td>00298</td></tr>\n",
       "\t<tr><td>Joan \"the bone\", Anne</td><td>Jet     </td><td>9th, at Terrace plc             </td><td>Desert City</td><td>CO</td><td>00123</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spec\\_tbl\\_df: 6 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " first\\_name & family\\_name & street\\_address & town & state & zip\\_code\\\\\n",
       " <chr> & <chr> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t John                  & Doe      & 120 jefferson st.                & Riverside   & NJ & 08075\\\\\n",
       "\t Jack                  & McGinnis & 220 hobo Av.                     & Phila       & PA & 09119\\\\\n",
       "\t John \"Da Man\"         & Repici   & 120 Jefferson St.                & Riverside   & NJ & 08075\\\\\n",
       "\t Stephen               & Tyler    & 7452 Terrace \"At the Plaza\" road & SomeTown    & SD & 91234\\\\\n",
       "\t NA                    & Blankman & NA                               & SomeTown    & SD & 00298\\\\\n",
       "\t Joan \"the bone\", Anne & Jet      & 9th, at Terrace plc              & Desert City & CO & 00123\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spec_tbl_df: 6 × 6\n",
       "\n",
       "| first_name &lt;chr&gt; | family_name &lt;chr&gt; | street_address &lt;chr&gt; | town &lt;chr&gt; | state &lt;chr&gt; | zip_code &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| John                  | Doe      | 120 jefferson st.                | Riverside   | NJ | 08075 |\n",
       "| Jack                  | McGinnis | 220 hobo Av.                     | Phila       | PA | 09119 |\n",
       "| John \"Da Man\"         | Repici   | 120 Jefferson St.                | Riverside   | NJ | 08075 |\n",
       "| Stephen               | Tyler    | 7452 Terrace \"At the Plaza\" road | SomeTown    | SD | 91234 |\n",
       "| NA                    | Blankman | NA                               | SomeTown    | SD | 00298 |\n",
       "| Joan \"the bone\", Anne | Jet      | 9th, at Terrace plc              | Desert City | CO | 00123 |\n",
       "\n"
      ],
      "text/plain": [
       "  first_name            family_name street_address                  \n",
       "1 John                  Doe         120 jefferson st.               \n",
       "2 Jack                  McGinnis    220 hobo Av.                    \n",
       "3 John \"Da Man\"         Repici      120 Jefferson St.               \n",
       "4 Stephen               Tyler       7452 Terrace \"At the Plaza\" road\n",
       "5 NA                    Blankman    NA                              \n",
       "6 Joan \"the bone\", Anne Jet         9th, at Terrace plc             \n",
       "  town        state zip_code\n",
       "1 Riverside   NJ    08075   \n",
       "2 Phila       PA    09119   \n",
       "3 Riverside   NJ    08075   \n",
       "4 SomeTown    SD    91234   \n",
       "5 SomeTown    SD    00298   \n",
       "6 Desert City CO    00123   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names_variables <- c(\"first_name\", \"family_name\", \"street_address\", \"town\", \"state\", \"zip_code\")\n",
    "\n",
    "addresses <-  \"addresses.csv\" %>%\n",
    "               read_csv(col_names = names_variables) \n",
    "\n",
    "addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try again giving different names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A spec_tbl_df: 6 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>first_name</th><th scope=col>family_name</th><th scope=col>street_address</th><th scope=col>town</th><th scope=col>ST</th><th scope=col>ZIP</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>John                 </td><td>Doe     </td><td>120 jefferson st.               </td><td>Riverside  </td><td>NJ</td><td>08075</td></tr>\n",
       "\t<tr><td>Jack                 </td><td>McGinnis</td><td>220 hobo Av.                    </td><td>Phila      </td><td>PA</td><td>09119</td></tr>\n",
       "\t<tr><td>John \"Da Man\"        </td><td>Repici  </td><td>120 Jefferson St.               </td><td>Riverside  </td><td>NJ</td><td>08075</td></tr>\n",
       "\t<tr><td>Stephen              </td><td>Tyler   </td><td>7452 Terrace \"At the Plaza\" road</td><td>SomeTown   </td><td>SD</td><td>91234</td></tr>\n",
       "\t<tr><td>NA                   </td><td>Blankman</td><td>NA                              </td><td>SomeTown   </td><td>SD</td><td>00298</td></tr>\n",
       "\t<tr><td>Joan \"the bone\", Anne</td><td>Jet     </td><td>9th, at Terrace plc             </td><td>Desert City</td><td>CO</td><td>00123</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spec\\_tbl\\_df: 6 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " first\\_name & family\\_name & street\\_address & town & ST & ZIP\\\\\n",
       " <chr> & <chr> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t John                  & Doe      & 120 jefferson st.                & Riverside   & NJ & 08075\\\\\n",
       "\t Jack                  & McGinnis & 220 hobo Av.                     & Phila       & PA & 09119\\\\\n",
       "\t John \"Da Man\"         & Repici   & 120 Jefferson St.                & Riverside   & NJ & 08075\\\\\n",
       "\t Stephen               & Tyler    & 7452 Terrace \"At the Plaza\" road & SomeTown    & SD & 91234\\\\\n",
       "\t NA                    & Blankman & NA                               & SomeTown    & SD & 00298\\\\\n",
       "\t Joan \"the bone\", Anne & Jet      & 9th, at Terrace plc              & Desert City & CO & 00123\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spec_tbl_df: 6 × 6\n",
       "\n",
       "| first_name &lt;chr&gt; | family_name &lt;chr&gt; | street_address &lt;chr&gt; | town &lt;chr&gt; | ST &lt;chr&gt; | ZIP &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| John                  | Doe      | 120 jefferson st.                | Riverside   | NJ | 08075 |\n",
       "| Jack                  | McGinnis | 220 hobo Av.                     | Phila       | PA | 09119 |\n",
       "| John \"Da Man\"         | Repici   | 120 Jefferson St.                | Riverside   | NJ | 08075 |\n",
       "| Stephen               | Tyler    | 7452 Terrace \"At the Plaza\" road | SomeTown    | SD | 91234 |\n",
       "| NA                    | Blankman | NA                               | SomeTown    | SD | 00298 |\n",
       "| Joan \"the bone\", Anne | Jet      | 9th, at Terrace plc              | Desert City | CO | 00123 |\n",
       "\n"
      ],
      "text/plain": [
       "  first_name            family_name street_address                  \n",
       "1 John                  Doe         120 jefferson st.               \n",
       "2 Jack                  McGinnis    220 hobo Av.                    \n",
       "3 John \"Da Man\"         Repici      120 Jefferson St.               \n",
       "4 Stephen               Tyler       7452 Terrace \"At the Plaza\" road\n",
       "5 NA                    Blankman    NA                              \n",
       "6 Joan \"the bone\", Anne Jet         9th, at Terrace plc             \n",
       "  town        ST ZIP  \n",
       "1 Riverside   NJ 08075\n",
       "2 Phila       PA 09119\n",
       "3 Riverside   NJ 08075\n",
       "4 SomeTown    SD 91234\n",
       "5 SomeTown    SD 00298\n",
       "6 Desert City CO 00123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "addresses %>% rename(\n",
    "    ST = state,\n",
    "    ZIP = zip_code\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Col types\n",
    "\n",
    "Not all columns are the same stuff. Just by looking at the code, what do you expect the type of the data for each column to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Expect all character except zip code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare your previous answer with the type of the data in the columns that you can discover using, for example, `glimpse()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 6\n",
      "Columns: 6\n",
      "$ first_name     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"John\", \"Jack\", \"John \\\"Da Man\\\"\", \"Stephen\", NA, \"Joan…\n",
      "$ family_name    \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Doe\", \"McGinnis\", \"Repici\", \"Tyler\", \"Blankman\", \"Jet\"\n",
      "$ street_address \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"120 jefferson st.\", \"220 hobo Av.\", \"120 Jefferson St.…\n",
      "$ town           \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Riverside\", \"Phila\", \"Riverside\", \"SomeTown\", \"SomeTow…\n",
      "$ state          \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"NJ\", \"PA\", \"NJ\", \"SD\", \"SD\", \"CO\"\n",
      "$ zip_code       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"08075\", \"09119\", \"08075\", \"91234\", \"00298\", \"00123\"\n"
     ]
    }
   ],
   "source": [
    "addresses %>% glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No they were all parsed as character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there was one column which may have confused you: the zip code. Those looks like numbers, integers to be specific.  \n",
    "\n",
    "Yet some of them have zeros in front of the other digits. For an integer, that should not be a big problem, we can understand how to read the following number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "19"
      ],
      "text/latex": [
       "19"
      ],
      "text/markdown": [
       "19"
      ],
      "text/plain": [
       "[1] 19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "0019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet, `readr` is more careful. Instead of risking an error forcing stuff to be a number when it was not, it parses `0019` as _characters_: readr is the name of the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'0019'"
      ],
      "text/latex": [
       "'0019'"
      ],
      "text/markdown": [
       "'0019'"
      ],
      "text/plain": [
       "[1] \"0019\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"0019\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a preview of what kind of object `read_csv()` will produce by using `guess_parser()`. Consider the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'character'"
      ],
      "text/latex": [
       "'character'"
      ],
      "text/markdown": [
       "'character'"
      ],
      "text/plain": [
       "[1] \"character\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'double'"
      ],
      "text/latex": [
       "'double'"
      ],
      "text/markdown": [
       "'double'"
      ],
      "text/plain": [
       "[1] \"double\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'double'"
      ],
      "text/latex": [
       "'double'"
      ],
      "text/markdown": [
       "'double'"
      ],
      "text/plain": [
       "[1] \"double\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'number'"
      ],
      "text/latex": [
       "'number'"
      ],
      "text/markdown": [
       "'number'"
      ],
      "text/plain": [
       "[1] \"number\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'date'"
      ],
      "text/latex": [
       "'date'"
      ],
      "text/markdown": [
       "'date'"
      ],
      "text/plain": [
       "[1] \"date\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'date'"
      ],
      "text/latex": [
       "'date'"
      ],
      "text/markdown": [
       "'date'"
      ],
      "text/plain": [
       "[1] \"date\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"0019\" %>% guess_parser()\n",
    "\"19\" %>% guess_parser()\n",
    "\"1.9\" %>% guess_parser()\n",
    "\"1,9\" %>% guess_parser()\n",
    "\"1900-03-01\" %>% guess_parser()\n",
    "\"1900-33-33\" %>% guess_parser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`readr` tries to guess the type of the values it reads in a file, but he does not ALWAYS get it right. Moreover, it does not guess after having read _all_ the rows (that would be inefficient). It reads only a certain number of them, and then guesses and reads the other rows hoping that they are of the same type.\n",
    "\n",
    "To be rigorous: it guesses the _schema_ (do you remember from the first lecture?) and then uses it to read efficiently the csv. `read_csv()` can read stuff from a file on your hard drive or from the web. It can even read compressed (zipped) files without any trouble (if they are in good shape). In general, if something is not *surely* of some other kind, it gets parsed as character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m23175\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m10\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (9): Industry_aggregation_NZSIOC, Industry_code_NZSIOC, Industry_name_NZ...\n",
      "\u001b[32mdbl\u001b[39m (1): Year\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "url_enterprise_survey <- \"https://www.stats.govt.nz/assets/Uploads/Annual-enterprise-survey/Annual-enterprise-survey-2017-financial-year-provisional/Download-data/annual-enterprise-survey-2017-financial-year-provisional-csv.csv\"\n",
    "\n",
    "enterprise_survey <- read_csv(url_enterprise_survey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A spec_tbl_df: 5 × 10</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Year</th><th scope=col>Industry_aggregation_NZSIOC</th><th scope=col>Industry_code_NZSIOC</th><th scope=col>Industry_name_NZSIOC</th><th scope=col>Units</th><th scope=col>Variable_code</th><th scope=col>Variable_name</th><th scope=col>Variable_category</th><th scope=col>Value</th><th scope=col>Industry_code_ANZSIC06</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>2015</td><td>Level 3</td><td>EE12 </td><td>Heavy and Civil Engineering Construction         </td><td>Dollars (millions)</td><td>H22</td><td>Closing stocks              </td><td>Financial performance</td><td>178 </td><td>ANZSIC06 group E310                                   </td></tr>\n",
       "\t<tr><td>2013</td><td>Level 4</td><td>FF116</td><td>Commission Based Wholesaling                     </td><td>Percentage        </td><td>H36</td><td>Current ratio               </td><td>Financial ratios     </td><td>158 </td><td>ANZSIC06 Group F380                                   </td></tr>\n",
       "\t<tr><td>2014</td><td>Level 1</td><td>QQ   </td><td>Health Care and Social Assistance                </td><td>Dollars (millions)</td><td>H20</td><td>Non-operating expenses      </td><td>Financial performance</td><td>138 </td><td>ANZSIC06 division Q                                   </td></tr>\n",
       "\t<tr><td>2014</td><td>Level 3</td><td>CC52 </td><td>Basic Chemical and Chemical Product Manufacturing</td><td>Dollars (millions)</td><td>H30</td><td>Total equity and liabilities</td><td>Financial position   </td><td>4438</td><td>ANZSIC06 groups C181, C182, C183, C184, C185, and C189</td></tr>\n",
       "\t<tr><td>2013</td><td>Level 4</td><td>FF114</td><td>Grocery, Liquor and Tobacco Product Wholesaling  </td><td>Dollars (millions)</td><td>H29</td><td>Other assets                </td><td>Financial position   </td><td>1547</td><td>ANZSIC06 group F360                                   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spec\\_tbl\\_df: 5 × 10\n",
       "\\begin{tabular}{llllllllll}\n",
       " Year & Industry\\_aggregation\\_NZSIOC & Industry\\_code\\_NZSIOC & Industry\\_name\\_NZSIOC & Units & Variable\\_code & Variable\\_name & Variable\\_category & Value & Industry\\_code\\_ANZSIC06\\\\\n",
       " <dbl> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t 2015 & Level 3 & EE12  & Heavy and Civil Engineering Construction          & Dollars (millions) & H22 & Closing stocks               & Financial performance & 178  & ANZSIC06 group E310                                   \\\\\n",
       "\t 2013 & Level 4 & FF116 & Commission Based Wholesaling                      & Percentage         & H36 & Current ratio                & Financial ratios      & 158  & ANZSIC06 Group F380                                   \\\\\n",
       "\t 2014 & Level 1 & QQ    & Health Care and Social Assistance                 & Dollars (millions) & H20 & Non-operating expenses       & Financial performance & 138  & ANZSIC06 division Q                                   \\\\\n",
       "\t 2014 & Level 3 & CC52  & Basic Chemical and Chemical Product Manufacturing & Dollars (millions) & H30 & Total equity and liabilities & Financial position    & 4438 & ANZSIC06 groups C181, C182, C183, C184, C185, and C189\\\\\n",
       "\t 2013 & Level 4 & FF114 & Grocery, Liquor and Tobacco Product Wholesaling   & Dollars (millions) & H29 & Other assets                 & Financial position    & 1547 & ANZSIC06 group F360                                   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spec_tbl_df: 5 × 10\n",
       "\n",
       "| Year &lt;dbl&gt; | Industry_aggregation_NZSIOC &lt;chr&gt; | Industry_code_NZSIOC &lt;chr&gt; | Industry_name_NZSIOC &lt;chr&gt; | Units &lt;chr&gt; | Variable_code &lt;chr&gt; | Variable_name &lt;chr&gt; | Variable_category &lt;chr&gt; | Value &lt;chr&gt; | Industry_code_ANZSIC06 &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 2015 | Level 3 | EE12  | Heavy and Civil Engineering Construction          | Dollars (millions) | H22 | Closing stocks               | Financial performance | 178  | ANZSIC06 group E310                                    |\n",
       "| 2013 | Level 4 | FF116 | Commission Based Wholesaling                      | Percentage         | H36 | Current ratio                | Financial ratios      | 158  | ANZSIC06 Group F380                                    |\n",
       "| 2014 | Level 1 | QQ    | Health Care and Social Assistance                 | Dollars (millions) | H20 | Non-operating expenses       | Financial performance | 138  | ANZSIC06 division Q                                    |\n",
       "| 2014 | Level 3 | CC52  | Basic Chemical and Chemical Product Manufacturing | Dollars (millions) | H30 | Total equity and liabilities | Financial position    | 4438 | ANZSIC06 groups C181, C182, C183, C184, C185, and C189 |\n",
       "| 2013 | Level 4 | FF114 | Grocery, Liquor and Tobacco Product Wholesaling   | Dollars (millions) | H29 | Other assets                 | Financial position    | 1547 | ANZSIC06 group F360                                    |\n",
       "\n"
      ],
      "text/plain": [
       "  Year Industry_aggregation_NZSIOC Industry_code_NZSIOC\n",
       "1 2015 Level 3                     EE12                \n",
       "2 2013 Level 4                     FF116               \n",
       "3 2014 Level 1                     QQ                  \n",
       "4 2014 Level 3                     CC52                \n",
       "5 2013 Level 4                     FF114               \n",
       "  Industry_name_NZSIOC                              Units             \n",
       "1 Heavy and Civil Engineering Construction          Dollars (millions)\n",
       "2 Commission Based Wholesaling                      Percentage        \n",
       "3 Health Care and Social Assistance                 Dollars (millions)\n",
       "4 Basic Chemical and Chemical Product Manufacturing Dollars (millions)\n",
       "5 Grocery, Liquor and Tobacco Product Wholesaling   Dollars (millions)\n",
       "  Variable_code Variable_name                Variable_category     Value\n",
       "1 H22           Closing stocks               Financial performance 178  \n",
       "2 H36           Current ratio                Financial ratios      158  \n",
       "3 H20           Non-operating expenses       Financial performance 138  \n",
       "4 H30           Total equity and liabilities Financial position    4438 \n",
       "5 H29           Other assets                 Financial position    1547 \n",
       "  Industry_code_ANZSIC06                                \n",
       "1 ANZSIC06 group E310                                   \n",
       "2 ANZSIC06 Group F380                                   \n",
       "3 ANZSIC06 division Q                                   \n",
       "4 ANZSIC06 groups C181, C182, C183, C184, C185, and C189\n",
       "5 ANZSIC06 group F360                                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enterprise_survey %>% sample_n(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n",
    "\n",
    "Read something from the stats nz website:  https://www.stats.govt.nz/large-datasets/csv-files-for-download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m401772\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m10\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (8): year_month, month_of_release, passenger_type, direction, citizenshi...\n",
      "\u001b[32mdbl\u001b[39m (2): estimate, standard_error\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "url_migration <- \"https://www.stats.govt.nz/assets/Uploads/International-migration/International-migration-March-2021/Download-data/international-migration-March-2021-citizenship-by-visa-by-country-of-last-permanent-residence.csv\"\n",
    "migration <- read_csv(url_migration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 401,772\n",
      "Columns: 10\n",
      "$ year_month           \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"2020-02\", \"2020-09\", \"2020-07\", \"2020-07\", \"2020…\n",
      "$ month_of_release     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"2021-03\", \"2021-03\", \"2021-03\", \"2021-03\", \"2021…\n",
      "$ passenger_type       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Long-term migrant\", \"Long-term migrant\", \"Long-t…\n",
      "$ direction            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Arrivals\", \"Arrivals\", \"Arrivals\", \"Arrivals\", \"…\n",
      "$ citizenship          \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"non-NZ\", \"non-NZ\", \"non-NZ\", \"non-NZ\", \"NZ\", \"NZ…\n",
      "$ visa                 \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Resident\", \"Resident\", \"Visitor\", \"NZ and Austra…\n",
      "$ country_of_residence \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Andorra\", \"Andorra\", \"Andorra\", \"Andorra\", \"Ando…\n",
      "$ estimate             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1, 1, 1, 1, 1, 3, 1, 0, 0, 16, 6, 23, 19, 4, 2, 1…\n",
      "$ standard_error       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…\n",
      "$ status               \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Provisional\", \"Provisional\", \"Provisional\", \"Pro…\n"
     ]
    }
   ],
   "source": [
    "migration %>% glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 10 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>country_of_residence</th><th scope=col>Total_Arrivals</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>TOTAL                     </td><td>606544</td></tr>\n",
       "\t<tr><td>Asia                      </td><td>247183</td></tr>\n",
       "\t<tr><td>Oceania and Antarctica    </td><td>163662</td></tr>\n",
       "\t<tr><td>India                     </td><td>113914</td></tr>\n",
       "\t<tr><td>Australia                 </td><td> 84117</td></tr>\n",
       "\t<tr><td>Europe                    </td><td> 75507</td></tr>\n",
       "\t<tr><td>The Americas              </td><td> 45249</td></tr>\n",
       "\t<tr><td>Africa and the Middle East</td><td> 44992</td></tr>\n",
       "\t<tr><td>United Kingdom            </td><td> 35794</td></tr>\n",
       "\t<tr><td>Not Stated                </td><td> 29949</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 10 × 2\n",
       "\\begin{tabular}{ll}\n",
       " country\\_of\\_residence & Total\\_Arrivals\\\\\n",
       " <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t TOTAL                      & 606544\\\\\n",
       "\t Asia                       & 247183\\\\\n",
       "\t Oceania and Antarctica     & 163662\\\\\n",
       "\t India                      & 113914\\\\\n",
       "\t Australia                  &  84117\\\\\n",
       "\t Europe                     &  75507\\\\\n",
       "\t The Americas               &  45249\\\\\n",
       "\t Africa and the Middle East &  44992\\\\\n",
       "\t United Kingdom             &  35794\\\\\n",
       "\t Not Stated                 &  29949\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 10 × 2\n",
       "\n",
       "| country_of_residence &lt;chr&gt; | Total_Arrivals &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| TOTAL                      | 606544 |\n",
       "| Asia                       | 247183 |\n",
       "| Oceania and Antarctica     | 163662 |\n",
       "| India                      | 113914 |\n",
       "| Australia                  |  84117 |\n",
       "| Europe                     |  75507 |\n",
       "| The Americas               |  45249 |\n",
       "| Africa and the Middle East |  44992 |\n",
       "| United Kingdom             |  35794 |\n",
       "| Not Stated                 |  29949 |\n",
       "\n"
      ],
      "text/plain": [
       "   country_of_residence       Total_Arrivals\n",
       "1  TOTAL                      606544        \n",
       "2  Asia                       247183        \n",
       "3  Oceania and Antarctica     163662        \n",
       "4  India                      113914        \n",
       "5  Australia                   84117        \n",
       "6  Europe                      75507        \n",
       "7  The Americas                45249        \n",
       "8  Africa and the Middle East  44992        \n",
       "9  United Kingdom              35794        \n",
       "10 Not Stated                  29949        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "migration %>% filter(direction ==\"Arrivals\", year_month == \"2020-02\", passenger_type == \"Long-term migrant\") %>% group_by(country_of_residence) %>% summarise(Total_Arrivals = sum(estimate)) %>% arrange(desc(Total_Arrivals)) %>% head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When things go bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet, this can go wrong sometimes. In the two following examples we will encouter some issue and work out if we can safely ignore them or we need to correct them. Remember, the decision depends on what data you are working on and for what purpose.  \n",
    "Somebody else working on our examples may come to a different conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "Let's try with a big and wild csv from https://www.stats.govt.nz/large-datasets/csv-files-for-download/:\n",
    "\n",
    "`Overseas trade index: March 2020 quarter (provisional) – CSV.`\n",
    "\n",
    "Refer to the website to discover the meaning of the variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mNew names:\n",
      "\u001b[36m•\u001b[39m `` -> `...10`\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m58308\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m10\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (4): Harmonised System Description, Unit Qty, Country, Status\n",
      "\u001b[32mdbl\u001b[39m (2): Month, Harmonised System Code\n",
      "\u001b[33mlgl\u001b[39m (1): ...10\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cols(\n",
       "  Month = \u001b[32mcol_double()\u001b[39m,\n",
       "  `Harmonised System Code` = \u001b[32mcol_double()\u001b[39m,\n",
       "  `Harmonised System Description` = \u001b[31mcol_character()\u001b[39m,\n",
       "  `Unit Qty` = \u001b[31mcol_character()\u001b[39m,\n",
       "  Country = \u001b[31mcol_character()\u001b[39m,\n",
       "  `Imports ($NZD vfd)` = \u001b[32mcol_number()\u001b[39m,\n",
       "  `Imports ($NZD cif)` = \u001b[32mcol_number()\u001b[39m,\n",
       "  `Imports Qty` = \u001b[32mcol_number()\u001b[39m,\n",
       "  Status = \u001b[31mcol_character()\u001b[39m,\n",
       "  ...10 = \u001b[33mcol_logical()\u001b[39m\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_url <- \"https://www.stats.govt.nz/assets/Uploads/overseas-merchandise-trade-datasets/omt-datasets-june-2021/Jun-2021-Imports-HS10-by-Country.csv\"\n",
    "test <- test_url %>% read_csv()\n",
    "spec(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m93335\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m13\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (10): Series_reference, STATUS, UNITS, Subject, Group, Series_title_1, S...\n",
      "\u001b[32mdbl\u001b[39m  (3): Period, Data_value, MAGNTUDE\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "Overseas_ti_url <- \"https://www.stats.govt.nz/assets/Uploads/Overseas-trade-indexes-prices-and-volumes/Overseas-trade-indexes-prices-and-volumes-March-2020-quarter-provisional/Download-data/overseas-trade-indexes-march-2020-provisional.csv\"\n",
    "\n",
    "Overseas_ti <- Overseas_ti_url %>% read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cols(\n",
       "  Series_reference = \u001b[31mcol_character()\u001b[39m,\n",
       "  Period = \u001b[32mcol_double()\u001b[39m,\n",
       "  Data_value = \u001b[32mcol_double()\u001b[39m,\n",
       "  STATUS = \u001b[31mcol_character()\u001b[39m,\n",
       "  UNITS = \u001b[31mcol_character()\u001b[39m,\n",
       "  MAGNTUDE = \u001b[32mcol_double()\u001b[39m,\n",
       "  Subject = \u001b[31mcol_character()\u001b[39m,\n",
       "  Group = \u001b[31mcol_character()\u001b[39m,\n",
       "  Series_title_1 = \u001b[31mcol_character()\u001b[39m,\n",
       "  Series_title_2 = \u001b[31mcol_character()\u001b[39m,\n",
       "  Series_title_3 = \u001b[31mcol_character()\u001b[39m,\n",
       "  Series_title_4 = \u001b[31mcol_character()\u001b[39m,\n",
       "  Series_title_5 = \u001b[31mcol_character()\u001b[39m\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spec(Overseas_ti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually are no longer getting parsing warnings as the dataset has been fixed by STATSNZ. We can specify column parsing and try to understand what's going on. We are suggested us to use `problems()` for more details. Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:14:35: unexpected symbol\n13:   Series_title_4 = col_integer(),\n14:   Series_title_5 = col_character().\n                                      ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:14:35: unexpected symbol\n13:   Series_title_4 = col_integer(),\n14:   Series_title_5 = col_character().\n                                      ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "Overseas_ti <- Overseas_ti %>% read_csv(col_types = cols(\n",
    "  Series_reference = col_character(),\n",
    "  Period = col_double(),\n",
    "  Data_value = col_double(),\n",
    "  STATUS = col_character(),\n",
    "  UNITS = col_character(),\n",
    "  MAGNTUDE = col_double(),\n",
    "  Subject = col_character(),\n",
    "  Group = col_character(),\n",
    "  Series_title_1 = col_character(),\n",
    "  Series_title_2 = col_character(),\n",
    "  Series_title_3 = col_character(),\n",
    "  Series_title_4 = col_integer(),\n",
    "  Series_title_5 = col_character()\n",
    "))#gives a really long error code dont run this shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overseas_ti_alt %>%\n",
    "  problems() %>%\n",
    "  head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overseas_ti %>% slice(30860:30870)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At row 30862 and following `read_csv()` was expecting `1/0/T/F/TRUE/FALSE`, and if we look at the parsing information when we read, the last two columns are parsed as `Logical`. But what has it got? That look like a character?\n",
    "\n",
    "Notice, at this point we may want to observe some value around the problem. However, if you did take a look at the two suspected columns, they are empty. We would need to look at the original file! You can do that in different way, one is by going back to the terminal and use `cat` `head` and `tail`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two columns are completely empty. Area all the errors the same kind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overseas_ti %>% \n",
    "  problems() %>%\n",
    "  group_by(col,expected,actual) %>%\n",
    "  tally()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `vis_miss()` from `vis_dat` to get a grip of how the missings are distributed. (or you can install the package `nianar` and use one of its functions to plot the distribution of the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# install.packages(\"visdat\")\n",
    "library(visdat)\n",
    "Overseas_ti %>%\n",
    "  sample_n(10000)%>%\n",
    "vis_miss(large_data_size = 9e+07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hard Time Reflection\n",
    "\n",
    "You have (at least) three choices. Which one would you pick? Discuss and implement. \n",
    "1. drop the columns completely\n",
    "2. use them with NAs inside\n",
    "3. change the parsing of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Some other time you need to specify the type of the column by your self! We see that with an example from `readr`.\n",
    "\n",
    "We are going to use the csv \"challenge.csv\", that is in this folder. First, open it with Jupyter Lab and give it a look. Then, we read it in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge <- \"challenge.csv\" %>%\n",
    "              read_csv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of read. And a familiar error. Let's give a look to the problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge %>%\n",
    "  problems() %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trouble seems to start at row 1001. We can ask `read_csv()` to read only a bunch of lines, not all of them, and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"challenge.csv\" %>%\n",
    "  read_csv(n_max = 1000) # we read only the first 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can skip the first 1000 rows and read from the rest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"challenge.csv\" %>%\n",
    "  read_csv(skip = 1001, # we skip the first 1000\n",
    "  col_names = c(\"x\", \"y\")) # now we have to specify the name of the columns as we have skip over the title row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first entries of the variable `x` before row 1001 seem to be integer. But then (see the `actual` column in challenge's problems) it changes. In fact, `read_csv()` reads the first 1000 rows and then guess the type of the columns. In this case, the type changes after that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can solve this in two ways: by specifying the type of the columns or by asking `read_csv()` to read more rows before guessing.\n",
    "\n",
    "We start with the latter. Go back an read the message that you got from `read_csv`, in particular the \"Parsed with column specification\" bit. That's the attempt done by `read_csv()`:\n",
    "\n",
    "```\n",
    "cols(\n",
    "  x = col_integer(),\n",
    "  y = col_character()\n",
    ")\n",
    "```\n",
    "\n",
    "You can copy and tweak it: change integer to double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge <- \"challenge.csv\" %>%\n",
    "  read_csv(col_types = cols(\n",
    "      x = col_double(), # change this to col_double\n",
    "      y = col_character()\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No red messages, yet we are not satisfied. Consider now the variable `y`. In the slice of challenge we saw before, it looks like `y` is actually a date. Read challenge.csv again, this tim specifying that y is a date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge <- \"challenge.csv\" %>%\n",
    "  read_csv(col_types = cols(\n",
    "      x = col_double(), # change this to col_double\n",
    "      y = col_character()\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way is to ask read_csv to read more lines. You can do this by changing the `guess_max` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge <- \"challenge.csv\" %>%\n",
    "  read_csv(guess_max = 1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are we looking at? I have no idea :-) Let's plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge %>%\n",
    "drop_na() %>%\n",
    "  ggplot(aes(x = x, y = y)) +\n",
    "  geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably just noise..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn\n",
    "\n",
    "Try to read some other csv file from the stats nz website we used before. Do you find any error? Can you solve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in unzip(destfile): object 'destfile' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in unzip(destfile): object 'destfile' not found\nTraceback:\n",
      "1. read_csv(unzip(destfile))",
      "2. vroom::vroom(file, delim = \",\", col_names = col_names, col_types = col_types, \n .     col_select = {\n .         {\n .             col_select\n .         }\n .     }, id = id, .name_repair = name_repair, skip = skip, n_max = n_max, \n .     na = na, quote = quote, comment = comment, skip_empty_rows = skip_empty_rows, \n .     trim_ws = trim_ws, escape_double = TRUE, escape_backslash = FALSE, \n .     locale = locale, guess_max = guess_max, show_col_types = show_col_types, \n .     progress = progress, altrep = lazy, num_threads = num_threads)",
      "3. standardise_path(file)",
      "4. unzip(destfile)"
     ]
    }
   ],
   "source": [
    "#employment_url <- \"https://www.stats.govt.nz/assets/Uploads/Employment-indicators/Employment-indicators-June-2021/Download-data/employment-indicators-june-2021-csv-tables.zip\"\n",
    "#employment <- read_csv(unzip(employment_url), n_max = 10)\n",
    "#destfile = \"test.zip\"\n",
    "#curl::curl_download(employment_url, destfile)\n",
    "employment <- read_csv(unzip(destfile))\n",
    "spec(employment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read csvs, but you can also write them! The function is `write_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remotes::install_github(\"JoeyBernhardt/singer\")\n",
    "library(singer)\n",
    "\n",
    "singer_locations %>%\n",
    "  write_csv(\"singer_locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m10100\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m14\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (8): track_id, title, song_id, release, artist_id, artist_name, name, city\n",
      "\u001b[32mdbl\u001b[39m (6): year, duration, artist_hotttnesss, artist_familiarity, latitude, lo...\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "singer_from_file <- read_csv(\"singer_locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in ncol(x): object 'singer_locations' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in ncol(x): object 'singer_locations' not found\nTraceback:\n",
      "1. all_equal(singer_locations, singer_from_file)",
      "2. equal_data_frame(target, current, ignore_col_order = ignore_col_order, \n .     ignore_row_order = ignore_row_order, convert = convert)",
      "3. is_compatible_data_frame(x, y, ignore_col_order = ignore_col_order, \n .     convert = convert)",
      "4. ncol(x)"
     ]
    }
   ],
   "source": [
    "all_equal(singer_locations,singer_from_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All as expected. Let's try to break things ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV and its cousins\n",
    "\n",
    "We mentioned at the beginning that comma separeted value files are part of a large community. `readr` has other functions (which behave very similarly) for the other members of the family: discover them by typing `read_` and then hitting the _tab_ key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'read_' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'read_' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "read_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the syntax `?function` (where _function_ is the function you care about) to see what this other read_... functions are for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced: excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel files are not strictly separated files. If you are lucky they are, almost, an XML file: we will speak about them in the web as data labs and lectures. If you are not lucky, they are a mess.\n",
    "\n",
    "Whether you are lucky or not depends on how the person who decided to write the excel file. If they decided to simply use it as a table, with one table per sheet, no fancy fonts, colors, or other embellishments, then you might be lucky. Otherwise, you are not.\n",
    "\n",
    "In both cases, R has a variety of libraries to help you read and write excel files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lucky\n",
    "\n",
    "The first one we see is [**readxl**](https://readxl.tidyverse.org/). It is installed when you install tidyverse, but it is not loaded by default. So you need to load it (in the usual way). We are straight reading from challenge.xslx (the same example as before, so do expect the same error. But more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in \"challenge.xlsx\" %>% read_excel() %>% glimpse(): could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in \"challenge.xlsx\" %>% read_excel() %>% glimpse(): could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "library(readxl) # From Jenny Brian et al.\n",
    "\n",
    "\"challenge.xlsx\" %>%\n",
    "  read_excel() %>%\n",
    "  glimpse() # Expect a lot of red!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOW, that's a lot of error. Luckily, we know already how to solve. Don't we? It's again that error in guessing the type of columns.\n",
    "\n",
    "## Files:\n",
    "### Same location\n",
    "### Relative path\n",
    "### Absolute path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2,000\n",
      "Columns: 2\n",
      "$ x \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 404, 4172, 3004, 787, 37, 2332, 2489, 1449, 3665, 3863, 4374, 875, 1…\n",
      "$ y \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n"
     ]
    }
   ],
   "source": [
    "\"challenge.xlsx\" %>%\n",
    "  read_excel(guess_max = 1001) %>%\n",
    "  glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better.\n",
    "\n",
    "`readxl` works well when the data is tabular, i.e. it resemble closely a csv file and you hit lucky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unlucky\n",
    "\n",
    "If the original excel file is a glorious mess of colors, fonts, more than on table per sheet, and so on you may still be able to recover the information using [tidyxl](https://github.com/nacnudus/tidyxl). This one does not come with the tidyverse, and you need to install it.\n",
    "\n",
    "You might need to restart your R kernel here, if Rcpp need to be upgraded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/home/patricio/R/x86_64-pc-linux-gnu-library/4.1’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "also installing the dependency ‘piton’\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tidyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file \"titanic.xlsx\" with excel (or numbers or any other spreadsheet program) and look at its structure. Then open it with tidyxl. Instead of producing a table, every non-empty cell in the excel file is recorded with its address (row number and column letter in excel), the content, the colour, and all its information. Then it is up to you to use that information wisely :-) This is one of the most advanced areas of wrangling, it is so because spreadsheet offer a lot of freedom to users, and users use all that freedom to write data in very creative ways. Your task is often that of taming that creativity and producing a rigidly structured dataframe. It is hard job.\n",
    "\n",
    "A good resource is this online free book by the developers of `tidyxl` (and `unpivotr`): https://nacnudus.github.io/spreadsheet-munging-strategies/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60\n",
      "Columns: 21\n",
      "$ sheet               \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Sheet1\", \"Sheet1\", \"Sheet1\", \"Sheet1\", \"Sheet1\", …\n",
      "$ address             \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"C1\", \"D1\", \"E1\", \"F1\", \"G1\", \"C2\", \"D2\", \"E2\", \"F…\n",
      "$ row                 \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 4,…\n",
      "$ col                 \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 3, 4, 5, 6, 7, 3, 4, 5, 6, 7, 1, 2, 1, 2, 4, 5, 6,…\n",
      "$ is_blank            \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FAL…\n",
      "$ data_type           \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"character\", \"character\", \"blank\", \"character\", \"b…\n",
      "$ error               \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n",
      "$ logical             \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n",
      "$ numeric             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n",
      "$ date                \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n",
      "$ character           \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Age\", \"Child\", NA, \"Adult\", NA, \"Survived\", \"No\",…\n",
      "$ character_formatted \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m [<tbl_df[1 x 14]>], [<tbl_df[1 x 14]>], <NULL>, […\n",
      "$ formula             \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n",
      "$ is_array            \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n",
      "$ formula_ref         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n",
      "$ formula_group       \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n",
      "$ comment             \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n",
      "$ height              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15…\n",
      "$ width               \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 8.38, 8.38, 8.38, 8.38, 8.38, 8.38, 8.38, 8.38, 8.…\n",
      "$ style_format        \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Normal\", …\n",
      "$ local_format_id     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 2, 3, 3, 1, 1, 1,…\n"
     ]
    }
   ],
   "source": [
    "library(tidyxl)\n",
    "titanic <- xlsx_cells(\"titanic.xlsx\")\n",
    "titanic %>% glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to look at the 1st row and ist content, we can operate on `titanic` (which is dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1\n",
      "Columns: 21\n",
      "$ sheet               \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Sheet1\"\n",
      "$ address             \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"C1\"\n",
      "$ row                 \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 1\n",
      "$ col                 \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 3\n",
      "$ is_blank            \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m FALSE\n",
      "$ data_type           \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"character\"\n",
      "$ error               \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m NA\n",
      "$ logical             \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m NA\n",
      "$ numeric             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m NA\n",
      "$ date                \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m NA\n",
      "$ character           \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Age\"\n",
      "$ character_formatted \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m [<tbl_df[1 x 14]>]\n",
      "$ formula             \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m NA\n",
      "$ is_array            \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m FALSE\n",
      "$ formula_ref         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m NA\n",
      "$ formula_group       \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m NA\n",
      "$ comment             \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m NA\n",
      "$ height              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 15\n",
      "$ width               \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 8.38\n",
      "$ style_format        \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Normal\"\n",
      "$ local_format_id     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 2\n"
     ]
    }
   ],
   "source": [
    "titanic %>%\n",
    "  slice(1) %>%\n",
    "  glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only non empty cell in the first row is the \"C1\" (row 1, col 3). It contains some characters. Let's extract its text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 1 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>address</th><th scope=col>row</th><th scope=col>col</th><th scope=col>character</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>C1</td><td>1</td><td>3</td><td>Age</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 4\n",
       "\\begin{tabular}{llll}\n",
       " address & row & col & character\\\\\n",
       " <chr> & <int> & <int> & <chr>\\\\\n",
       "\\hline\n",
       "\t C1 & 1 & 3 & Age\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 4\n",
       "\n",
       "| address &lt;chr&gt; | row &lt;int&gt; | col &lt;int&gt; | character &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| C1 | 1 | 3 | Age |\n",
       "\n"
      ],
      "text/plain": [
       "  address row col character\n",
       "1 C1      1   3   Age      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic %>%\n",
    "  slice(1) %>%\n",
    "  select(address,row,col,character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn, try with another row and see what it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to become a excel-to-R ninja (which is quite a good idea, given the amount of valuable data sleeping in companies' excel files) read more. Similar project you may want to look into are [unpivotr](https://nacnudus.github.io/unpivotr/) and [jailbreaker](https://github.com/rsheets/jailbreakr)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write excel\n",
    "\n",
    "If you ever want to write to an excel (maybe because your colleague do work just using excel and you are trying to bring smoothly them to R), [writexl](https://github.com/ropensci/writexl) is what you are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"writexl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The behaviour of its main function `write_xlsx()` is similar to `write_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'writexl' was built under R version 3.6.3\"\n"
     ]
    }
   ],
   "source": [
    "library(writexl)\n",
    "challenge %>% write_xlsx(path = \"challenge.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2,000\n",
      "Columns: 2\n",
      "$ x \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 404, 4172, 3004, 787, 37, 2332, 2489, 1449, 3665, 3863, 4374, 875, 1~\n",
      "$ y \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n"
     ]
    }
   ],
   "source": [
    "read_excel(\"challenge.xlsx\",\n",
    "          guess_max = 1001) %>%\n",
    "glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
